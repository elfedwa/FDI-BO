#!/bin/bash -l
#SBATCH --job-name={{job_name}}
#SBATCH --time={{job_time}}
## Number of MPI tasks (MPI)
#SBATCH --nodes={{nnode}} 
#SBATCH --ntasks-per-node=48

#SBATCH --ntasks={{ncpu}} 
#SBATCH --mem-per-cpu=2000MB
#SBATCH --no-requeue
#SBATCH --mail-type=ALL
#SBATCH --exclusive
#SBATCH --partition=l_long
#SBATCH --qos=ll
 
##Set OMP_NUM_THREADS to the same value as -c
##with a fallback in case it isn't set.
##SLURM_CPUS_PER_TASK is set to the value of -c, but only if -c is explicitly set
if [ -n "$SLURM_CPUS_PER_TASK" ]; then
  omp_threads=$SLURM_CPUS_PER_TASK
else
  omp_threads=1
fi
export OMP_NUM_THREADS=$omp_threads
echo "OMP_NUM_THREADS=" $omp_threads
 
#========================================
# load modules and run simulation
#module load slurm
module switch PrgEnv-cray PrgEnv-intel
module unload cray-libsci
source /lustre/opt/compilers/intel/cluster/17.1/parallel_studio_xe_2017.1.043/psxevars.sh
export INTEL_VERSION=17.0.4.196
 
 
VASP_BIN=/lustre/home/hepark054/Packages/VASP/vasp.5.4.1/bin/
srun --hint=nomultithread $VASP_BIN/{{cmd}} >& vasp.log
